{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0mr8FVxG1uR"
   },
   "source": [
    "### Reset GG Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SRHo5izGuvA"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxUwam0yu-8X"
   },
   "source": [
    "### **Install necessary lib and perform authorization (twice verification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2366
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 220651,
     "status": "ok",
     "timestamp": 1536862370304,
     "user": {
      "displayName": "Tiệp Nguyễn Vinh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113264793629815496186"
     },
     "user_tz": -420
    },
    "id": "FiUkuekZvVLC",
    "outputId": "95793a57-8663-4875-ca29-1c1547d8a86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preconfiguring packages ...\n",
      "Selecting previously unselected package cron.\n",
      "(Reading database ... 18408 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
      "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
      "Selecting previously unselected package libapparmor1:amd64.\n",
      "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
      "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
      "Selecting previously unselected package dbus.\n",
      "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
      "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
      "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
      "Selecting previously unselected package distro-info-data.\n",
      "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
      "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
      "Selecting previously unselected package libkmod2:amd64.\n",
      "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
      "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
      "Selecting previously unselected package kmod.\n",
      "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
      "Unpacking kmod (24-1ubuntu2) ...\n",
      "Selecting previously unselected package lsb-release.\n",
      "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
      "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
      "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
      "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
      "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
      "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
      "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
      "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
      "Selecting previously unselected package iso-codes.\n",
      "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
      "Unpacking iso-codes (3.75-1) ...\n",
      "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
      "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
      "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
      "Selecting previously unselected package python-apt-common.\n",
      "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
      "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
      "Selecting previously unselected package python3-apt.\n",
      "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
      "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
      "Selecting previously unselected package python3-dbus.\n",
      "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
      "Unpacking python3-dbus (1.2.4-1build3) ...\n",
      "Selecting previously unselected package python3-gi.\n",
      "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
      "Unpacking python3-gi (3.24.1-2build1) ...\n",
      "Selecting previously unselected package module-init-tools.\n",
      "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
      "Unpacking module-init-tools (24-1ubuntu2) ...\n",
      "Selecting previously unselected package python-apt.\n",
      "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
      "Unpacking python-apt (1.4.0~beta3build2) ...\n",
      "Selecting previously unselected package python-pycurl.\n",
      "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
      "Unpacking python-pycurl (7.43.0-2build2) ...\n",
      "Selecting previously unselected package python-software-properties.\n",
      "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
      "Unpacking python-software-properties (0.96.24.17) ...\n",
      "Selecting previously unselected package python3-software-properties.\n",
      "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
      "Unpacking python3-software-properties (0.96.24.17) ...\n",
      "Selecting previously unselected package software-properties-common.\n",
      "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
      "Unpacking software-properties-common (0.96.24.17) ...\n",
      "Selecting previously unselected package unattended-upgrades.\n",
      "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
      "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
      "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
      "Setting up python3-apt (1.4.0~beta3build2) ...\n",
      "Setting up iso-codes (3.75-1) ...\n",
      "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
      "Setting up python-pycurl (7.43.0-2build2) ...\n",
      "Setting up lsb-release (9.20160110ubuntu5) ...\n",
      "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
      "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
      "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
      "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
      "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
      "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
      "\n",
      "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
      "\n",
      "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
      "Setting up cron (3.0pl1-128ubuntu5) ...\n",
      "Adding group `crontab' (GID 102) ...\n",
      "Done.\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
      "Setting up kmod (24-1ubuntu2) ...\n",
      "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
      "Setting up python3-gi (3.24.1-2build1) ...\n",
      "Setting up module-init-tools (24-1ubuntu2) ...\n",
      "Setting up python3-software-properties (0.96.24.17) ...\n",
      "Setting up dbus (1.10.22-1ubuntu1) ...\n",
      "Setting up python-apt (1.4.0~beta3build2) ...\n",
      "Setting up python3-dbus (1.2.4-1build3) ...\n",
      "Setting up python-software-properties (0.96.24.17) ...\n",
      "Setting up software-properties-common (0.96.24.17) ...\n",
      "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
      "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
      "gpg: keybox '/tmp/tmpar8bvp0n/pubring.gpg' created\n",
      "gpg: /tmp/tmpar8bvp0n/trustdb.gpg: trustdb created\n",
      "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
      "gpg: Total number processed: 1\n",
      "gpg:               imported: 1\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "Selecting previously unselected package libfuse2:amd64.\n",
      "(Reading database ... 19816 files and directories currently installed.)\n",
      "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
      "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
      "Selecting previously unselected package fuse.\n",
      "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
      "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
      "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
      "Setting up fuse (2.9.7-1ubuntu1) ...\n",
      "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISeRjI07u-4Z"
   },
   "source": [
    "### **Kết nối vào Google Drive để lưu hoặc load model (nếu có)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIA1SzlNvuNC"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DV4UoC0WufBx"
   },
   "source": [
    "###  Kiểm tra thông tin GPU Cloud, ta thấy là bộ nhớ được cung cấp khoảng 12GB và notebook đã có thể sử dụng Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1924
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18081,
     "status": "ok",
     "timestamp": 1536862598160,
     "user": {
      "displayName": "Tiệp Nguyễn Vinh",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113264793629815496186"
     },
     "user_tz": -420
    },
    "id": "ZOkaFxpEvuJ7",
    "outputId": "5e53e1d9-52cb-4bf7-ce40-58a684cae2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device:  /device:GPU:0\n",
      "\n",
      "MemTotal:       13335236 kB\n",
      "MemFree:          226520 kB\n",
      "MemAvailable:   11670440 kB\n",
      "Buffers:          194292 kB\n",
      "Cached:         11404804 kB\n",
      "SwapCached:            0 kB\n",
      "Active:          1672516 kB\n",
      "Inactive:       10815292 kB\n",
      "Active(anon):    1036200 kB\n",
      "Inactive(anon):    84620 kB\n",
      "Active(file):     636316 kB\n",
      "Inactive(file): 10730672 kB\n",
      "Unevictable:           0 kB\n",
      "Mlocked:               0 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:              1496 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:        887056 kB\n",
      "Mapped:           416876 kB\n",
      "Shmem:            257020 kB\n",
      "Slab:             441692 kB\n",
      "SReclaimable:     403060 kB\n",
      "SUnreclaim:        38632 kB\n",
      "KernelStack:        3744 kB\n",
      "PageTables:         7524 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:     6667616 kB\n",
      "Committed_AS:    2720644 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:           0 kB\n",
      "VmallocChunk:          0 kB\n",
      "AnonHugePages:         0 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "DirectMap4k:      188404 kB\n",
      "DirectMap2M:     9248768 kB\n",
      "DirectMap1G:     6291456 kB\n",
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2200.000\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms rtm rdseed adx smap xsaveopt\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 l1tf\n",
      "bogomips\t: 4400.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2200.000\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms rtm rdseed adx smap xsaveopt\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 l1tf\n",
      "bogomips\t: 4400.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "Name: tensorflow\n",
      "Version: 1.10.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: opensource@google.com\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: wheel, astor, six, tensorboard, numpy, protobuf, absl-py, setuptools, gast, termcolor, grpcio\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print('Current Device: ', tf.test.gpu_device_name() + '\\n')\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "# RAM: \n",
    "!cat /proc/meminfo\n",
    "# CPU: \n",
    "!cat /proc/cpuinfo\n",
    "  \n",
    "# Tensorflow version\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCQiROFfJowQ"
   },
   "source": [
    "##Bắt đầu chương trình##\n",
    "Các bước trước, các bạn đã tạo kết nối, chứng thực tài khoản, kết nối GG Drive và test thử con GPU vừa được cấp phát.\n",
    "\n",
    "Đến bước này, các bạn đã thực sự bắt đầu chương trình của chính mình tạo ra. Khai báo lớp đối tượng DataSet dùng để lấy dữ liệu từ internet về và load vào đối tượng của lớp DataSet. Đoạn source code này các bạn lấy từ file dataset.py và gần như không chỉnh sửa gì cả :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2agslZUziPG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "        self.train_data = mnist.train.images  # Returns np.array\n",
    "        self.train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "        self.eval_data = mnist.test.images  # Returns np.array\n",
    "        self.eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "        self.curr_training_step = 0\n",
    "        self.curr_test_step = 0\n",
    "\n",
    "    def get_train_set_size(self):\n",
    "        return self.train_data.shape[0]\n",
    "\n",
    "    def get_test_set_size(self):\n",
    "        return self.eval_data.shape[0]\n",
    "\n",
    "    def to_one_hot(self, X):\n",
    "        one_hot = np.zeros((len(X), 10))\n",
    "        for i in range(len(X)):\n",
    "            np.put(one_hot[i, :], X[i], 1)\n",
    "\n",
    "        return one_hot\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        X_train_bs = self.train_data[self.curr_training_step * batch_size:self.curr_training_step * batch_size + batch_size,:]\n",
    "        Y_train_bs = self.train_labels[self.curr_training_step * batch_size:self.curr_training_step * batch_size + batch_size]\n",
    "\n",
    "        self.curr_training_step = self.curr_training_step + 1\n",
    "        self.curr_training_step = self.curr_training_step if (\n",
    "            self.curr_training_step * batch_size < self.get_train_set_size()) else 0\n",
    "\n",
    "        return (X_train_bs, self.to_one_hot(Y_train_bs))\n",
    "\n",
    "    def next_batch_test(self, batch_size):\n",
    "        X_test_bs = self.eval_data[self.curr_test_step * batch_size:self.curr_test_step * batch_size + batch_size,:]\n",
    "        Y_test_bs = self.eval_labels[self.curr_test_step * batch_size:self.curr_test_step * batch_size + batch_size]\n",
    "        \n",
    "\n",
    "        self.curr_test_step = self.curr_test_step + 1\n",
    "        self.curr_test_step = self.curr_test_step if (self.curr_test_step * batch_size < self.get_test_set_size()) else 0\n",
    "\n",
    "        return (X_test_bs, self.to_one_hot(Y_test_bs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsFZD_yiK3Zo"
   },
   "source": [
    "## Thừa thắng, khai báo tiếp lớp đối tượng LeNet##\n",
    "Tương tự như ở bước trước, bước này ta có thể copy code từ file train.py vào và gần như không thay đổi dòng mã nguồn nào cả.\n",
    "\n",
    "Thực ra phần khai báo numpy và tensorflow là hơi thừa, do đã khai báo ở đằng trước. Tuy nhiên, không sao cả. Mình chỉ minh hoạ rằng, dùng Google Colab rất dễ, copy and paste và sau khi đã cấp phát GPU là chạy mà thôi.\n",
    "\n",
    "**LƯU Ý**: Chỉ có một chỗ duy nhất cần để ý đó là thư mục lưu trữ. Các bạn cần sử lại thành **\"drive/#path to the folder in GGDrive#\"**. Trong đó, từ 'drive' thể hiện thư mục gốc trên Google Drive của bạn. Phần <paht to the folder in GGDrive> là đường dẫn trên Drive để đến được thư mục muốn làm việc. Ví dụ nếu file .ipynb của bạn đặt ở thư mục GPU-Run, trong thư mục có thư mục model để chứa mô hình sau khi đã huấn luyện thì ta sẽ sửa lại: \n",
    "** model_dir = 'drive/GPU-Run/model'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pklCjhJ0ysKZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "### CHU Y: THAY DUONG DAN DEN THU MUC TREN Google Drive cua ban\n",
    "model_dir = 'drive/GPU-Run/model'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "class LeNet():\n",
    "  def __init__(self, weights=None, sess=None, log=True):\n",
    "    self.X = tf.placeholder(tf.float32, [None, 28, 28, 1], name='X')\n",
    "    self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    self.log = log\n",
    "    self.sess = sess\n",
    "\n",
    "    self.conv_layers()\n",
    "    self.fc_layers()\n",
    "\n",
    "    self.probs = tf.nn.softmax(self.logits, name='softmax')\n",
    "\n",
    "    if weights is not None and sess is not None:\n",
    "      self.load_weights(weights, sess)\n",
    "\n",
    "  def conv_layers(self):\n",
    "    self.parameters = []\n",
    "    images = self.X\n",
    "\n",
    "    # Layer 1: Conv\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "      kernel = tf.Variable(tf.random_normal([3, 3, 1, 32], dtype=tf.float32, stddev=1e-1, \n",
    "        name='weights'))\n",
    "      conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "      biases = tf.Variable(tf.constant(0.0, shape=[32], dtype=tf.float32),\n",
    "        trainable=True, name='biases')\n",
    "      out = tf.nn.bias_add(conv, biases)\n",
    "      self.conv1 = tf.nn.relu(out, name=scope)\n",
    "      self.parameters += [kernel, biases]\n",
    "\n",
    "    # Layer 1: Pooling\n",
    "    self.pool1 = tf.nn.max_pool(self.conv1,\n",
    "      ksize=[1,2,2,1],\n",
    "      strides=[1,2,2,1],\n",
    "      padding='SAME',\n",
    "      name='pool1')\n",
    "\n",
    "    # Layer 2: Conv\n",
    "    with tf.name_scope('conv2') as scope:\n",
    "      kernel = tf.Variable(tf.random_normal([3, 3, 32, 64], dtype=tf.float32, stddev=1e-1, name='weights'))\n",
    "      conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "      biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "        trainable=True, name='biases')\n",
    "      out = tf.nn.bias_add(conv, biases)\n",
    "      self.conv2 = tf.nn.relu(out, name=scope)\n",
    "      self.parameters += [kernel, biases]\n",
    "\n",
    "    # Layer 2: Pooling\n",
    "    self.pool2 = tf.nn.max_pool(self.conv2,\n",
    "      ksize=[1,2,2,1],\n",
    "      strides=[1,2,2,1],\n",
    "      padding='SAME',\n",
    "      name='pool2')\n",
    "\n",
    "  def fc_layers(self):\n",
    "    # fc1\n",
    "    with tf.name_scope('fc1') as scope:\n",
    "      shape = int(np.prod(self.pool2.get_shape()[1:]))\n",
    "      fc1w = tf.Variable(tf.random_normal([shape, 128],\n",
    "        dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "      fc1b = tf.Variable(tf.constant(1.0, shape=[128], dtype=tf.float32),\n",
    "        trainable=True, name='biases')\n",
    "      pool2_flat = tf.reshape(self.pool2, [-1, shape])\n",
    "      fc1l = tf.nn.bias_add(tf.matmul(pool2_flat, fc1w), fc1b)\n",
    "      self.fc1 = tf.nn.relu(fc1l)\n",
    "      self.dropout1 = tf.nn.dropout(self.fc1, keep_prob=self.keep_prob, name='dropout1')\n",
    "      self.parameters += [fc1w, fc1b]\n",
    "\n",
    "    # fc2\n",
    "    with tf.name_scope('fc2') as scope:\n",
    "      fc2w = tf.Variable(tf.random_normal([128, 10],\n",
    "        dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "      fc2b = tf.Variable(tf.constant(1.0, shape=[10], dtype=tf.float32),\n",
    "        trainable=True, name='biases')\n",
    "      fc2l = tf.nn.bias_add(tf.matmul(self.dropout1, fc2w), fc2b)\n",
    "      self.logits = tf.nn.relu(fc2l)\n",
    "      self.parameters += [fc2w, fc2b]\n",
    "\n",
    "  def load_weights(weights, sess):\n",
    "    None\n",
    "\n",
    "  def train(self, learning_rate, training_epochs, batch_size, keep_prob):\n",
    "    # Load dataset for training and testing\n",
    "    self.dataset = DataSet()\n",
    "\n",
    "    # Define size of output\n",
    "    self.Y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "    # Define cost function\n",
    "    self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "    # Define optimization method\n",
    "    self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "    # Start logger\n",
    "    if self.log:\n",
    "        tf.summary.scalar('cost', self.cost)\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.train_writer = tf.summary.FileWriter('./log_train', self.sess.graph)\n",
    "\n",
    "    self.sess.run(tf.global_variables_initializer())\n",
    "    self.sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    print('Training...')\n",
    "    weights = []\n",
    "    # For each epoch, feed training data and perform updating parameters\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        # Number of batches = size of training set / batch_size\n",
    "        total_batch = int(self.dataset.get_train_set_size() / batch_size)\n",
    "\n",
    "        # For each batch \n",
    "        for i in range(total_batch + 1):\n",
    "            # Get next batch to feed to the network\n",
    "            batch_xs, batch_ys = self.dataset.next_batch(batch_size)\n",
    "            feed_dict = {\n",
    "                self.X: batch_xs.reshape([batch_xs.shape[0], 28, 28, 1]),\n",
    "                self.Y: batch_ys,\n",
    "                self.keep_prob: keep_prob\n",
    "            }\n",
    "\n",
    "            weights, summary, c, _ = self.sess.run([self.parameters, self.merged, self.cost, self.optimizer],\n",
    "                                                   feed_dict=feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        if self.log:\n",
    "            self.train_writer.add_summary(summary, epoch + 1)\n",
    "\n",
    "        print('Epoch:', '%02d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Training finished!')\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    ### CHU Y: Chi can sua lai duong dan thu muc chua MODEL\n",
    "    save_path = saver.save(self.sess, model_dir + \"/mnist_lenet.ckpt\")\n",
    "    print(\"Trainned model is saved in file: %s\" % save_path)\n",
    "\n",
    "  def evaluate(self, batch_size, keep_prob):\n",
    "\n",
    "    self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "    self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "    N = self.dataset.get_test_set_size()\n",
    "    print('test.size', N);\n",
    "    correct_sample = 0\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_xs, batch_ys = self.dataset.next_batch_test(batch_size)\n",
    "\n",
    "        N_batch = batch_xs.shape[0]\n",
    "\n",
    "        feed_dict = {\n",
    "            self.X: batch_xs.reshape([N_batch, 28, 28, 1]),\n",
    "            self.Y: batch_ys,\n",
    "            self.keep_prob: keep_prob\n",
    "        }\n",
    "\n",
    "        correct = self.sess.run(self.accuracy, feed_dict=feed_dict)\n",
    "        correct_sample += correct * N_batch\n",
    "\n",
    "    test_accuracy = correct_sample / N\n",
    "\n",
    "    print(\"\\nAccuracy Evaluates\")\n",
    "    print(\"-\" * 30)\n",
    "    print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SS5cgInxLkov"
   },
   "source": [
    "##Tiến hành thí nghiệm##\n",
    "\n",
    "Để bắt đầu khởi tạo và chạy mô hình, ta gọi 5 dòng lệnh sau đây. Và như vậy là ta đã có thể sử dụng K80 (12GB memory) để có thể train mạng LeNet rồi. Thời gian để các bạn train 40 epoch chỉ mất 2 phút."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "SQvZoyMcy0fL",
    "outputId": "3ecdae39-2039-41aa-da5d-23fa33f7faea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "Training...\n",
      "Epoch: 02 cost = 0.220026862\n",
      "Epoch: 03 cost = 0.131963294\n",
      "Epoch: 04 cost = 0.095869466\n",
      "Epoch: 05 cost = 0.076893867\n",
      "Epoch: 06 cost = 0.064144858\n",
      "Epoch: 07 cost = 0.056597817\n",
      "Epoch: 08 cost = 0.049744936\n",
      "Epoch: 09 cost = 0.043758852\n",
      "Epoch: 10 cost = 0.039856849\n",
      "Epoch: 11 cost = 0.035404160\n",
      "Epoch: 12 cost = 0.031734507\n",
      "Epoch: 13 cost = 0.031378918\n",
      "Epoch: 14 cost = 0.028549319\n",
      "Epoch: 15 cost = 0.026436142\n",
      "Epoch: 16 cost = 0.025040999\n",
      "Epoch: 17 cost = 0.023261481\n",
      "Epoch: 18 cost = 0.020847021\n",
      "Epoch: 19 cost = 0.019771104\n",
      "Epoch: 20 cost = 0.017252670\n",
      "Epoch: 21 cost = 0.016569230\n",
      "Epoch: 22 cost = 0.016363664\n",
      "Epoch: 23 cost = 0.014983140\n",
      "Epoch: 24 cost = 0.014590157\n",
      "Epoch: 25 cost = 0.014470957\n",
      "Epoch: 26 cost = 0.014388366\n",
      "Epoch: 27 cost = 0.013914947\n",
      "Epoch: 28 cost = 0.012147818\n",
      "Epoch: 29 cost = 0.010867086\n",
      "Epoch: 30 cost = 0.009985350\n",
      "Epoch: 31 cost = 0.009789908\n",
      "Epoch: 32 cost = 0.009659835\n",
      "Epoch: 33 cost = 0.009433388\n",
      "Epoch: 34 cost = 0.008581062\n",
      "Epoch: 35 cost = 0.009237760\n",
      "Epoch: 36 cost = 0.007364719\n",
      "Epoch: 37 cost = 0.008119666\n",
      "Epoch: 38 cost = 0.007528433\n",
      "Epoch: 39 cost = 0.006881199\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "lenet = LeNet(sess=sess, weights=None)\n",
    "\n",
    "lenet.train(learning_rate=0.001, training_epochs=40, batch_size=1000, keep_prob=0.7)\n",
    "lenet.evaluate(batch_size=1000, keep_prob=0.7)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_Lab2_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
