{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 3 - CNN - Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6DN3gs3aT6Mg",
        "Oj4C8OMZT6Mh",
        "qO-PkgqyT6Mj",
        "CkbJdSYmT6Mk"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UuiKELEdT6MF"
      },
      "source": [
        "# Giới thiệu Convolution Nets\n",
        "\n",
        "Convolutional Neural Networks (CNN) là một trong những mô hình deep learning phổ biến nhất và có ảnh hưởng nhiều nhất trong cộng đồng Computer Vision. CNN được dùng trong trong nhiều bài toán như nhận dạng ảnh, phân tích video, ảnh MRI, hoặc cho bài các bài của lĩnh vực xử lý ngôn ngữ tự nhiên, và hầu hết đều giải quyết tốt các bài toán này. \n",
        "\n",
        "CNN cũng có lịch sử khá lâu đời. Kiến trúc gốc của mô hình CNN được giới thiệu bởi một nhà khoa học máy tính người Nhật vào năm 1980. Sau đó, năm 1998, Yan LeCun lần đầu huấn luyện mô hình CNN với thuật toán backpropagation cho bài toán nhận dạng chữ viết tay. Tuy nhiên, mãi đến năm 2012, khi một nhà khoa học máy tính người Ukraine Alex Krizhevsky (đệ của Geoffrey Hinton) xây dựng mô hình CNN (AlexNet) và sử dụng GPU để tăng tốc quá trình huấn luyện deep nets để đạt được top 1 trong cuộc thi Computer Vision thường niên ImageNet với độ lỗi phân lớp top 5 giảm hơn 10% so với những mô hình truyền thống trước đó, đã tạo nên làn sóng mãnh mẽ sử dụng deep CNN với sự hỗ trợ của GPU để giải quyết càng nhiều các vấn đề trong Computer Vision.\n",
        "\n",
        "# Bài Toán Phân loại Ảnh\n",
        "Phân loại ảnh là một bài toán quan trọng bậc nhất trong lĩnh vực Computer Vision. Chúng ta đã có rất nhiều nghiên cứu để giải quyết bài toán này bằng cách rút trích các đặc trưng rất phổ biến như SIFT, HOG rồi cho máy tính học nhưng những cách này tỏ ra không thực sự hiểu quả. Nhưng ngược lại, đối với con người, chúng ta lại có bản năng tuyệt vời để phân loại được những đối tượng trong khung cảnh xung quanh một cách dễ dàng.\n",
        "\n",
        "Dữ liệu đầu vào của bài toán là một bức ảnh. Một ảnh được biểu diễn bằng ma trận các giá trị. Mô hình phân lớp sẽ phải dự đoán được lớp của ảnh từ ma trận điểm ảnh này, ví dụ như ảnh đó là con mèo, chó, hay là chim.\n",
        "\n",
        "![](https://pbcquoc.github.io/images/cnn_input.png)\n",
        "\n",
        "# Nội dung \n",
        "Trong assignment này, mình sẽ hướng dẫn các bạn xây dựng mô hình CNN (Convolution Neural Nets) cho bài toán phân loại ảnh. Các bạn sẽ sử dụng tensorflow [eager execution](https://www.tensorflow.org/guide/eager) để xây dựng model, huấn luyện mô hình trên tập train và predict ảnh trong tập test. \n",
        "\n",
        "Assignment này sẽ có câú trúc như sau:\n",
        "1. Import/ Xử lý dữ liệu\n",
        "2. Xây dựng mô hình\n",
        "3. Huấn luyện mô hình\n",
        "4. Đánh giá mô hình\n",
        "5. Sử dụng mô hình đã huấn luyện để dự đoán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1noDSEH2T6MG"
      },
      "source": [
        "# Import thư viện\n",
        "\n",
        "Chúng ta sử dụng một số hàm cơ bản trong tensorflow, sklearn và phải enable tf eage execution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lpEf76pvT6MH",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.contrib.eager.python import tfe\n",
        "from PIL import Image\n",
        "\n",
        "tf.disable_eager_execution()\n",
        "tf.set_random_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-drPZYqT6MK"
      },
      "source": [
        "# Import và inspect dữ liệu\n",
        "Trong bài này, các bạn phải xây dựng mô hình để xác định các địa danh nổi tiếng trên lãnh thổ Việt Nam được mô tả trong bức ảnh. Tập dữ liệu huấn luyện bao gồm 10k ảnh, là một phần nhỏ của bộ dữ liệu trong cuộc thi ZaloAI năm 2018. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6kFHSLe3T6ML"
      },
      "source": [
        "## Download dữ liệu\n",
        "Bạn có thể sử dụng trực tiếp dữ liệu trên competition được host trên Kaggle: [VietAI Foundation Course - CNN Assignment](https://www.kaggle.com/c/vietai-fc-cnn-assignment/data)\n",
        "\n",
        "Hoặc tải dữ liệu xuống từ Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TCiEHjzHT6ML",
        "colab": {}
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id='1ycR7Aexe8xbZ8oEDsQwGc9SIiFklRpfu', dest_path='./data.zip', unzip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQQFKcGLC1ZK",
        "colab_type": "text"
      },
      "source": [
        "Dữ liệu tải xuống sẽ chứa trong folder `data`. Cấu trúc thư mục như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OgiAISfDBVD",
        "colab_type": "code",
        "outputId": "0778da5b-299e-4943-e9af-4794e7e67edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_dir = 'data'\n",
        "os.listdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'images', 'train.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkHAl5onDQjs",
        "colab_type": "text"
      },
      "source": [
        "Trong đó:\n",
        "- **images**: thư mục chứa tất cả các ảnh dùng cho việc huấn luyện và đánh giá\n",
        "- **train.csv**: file CSV chứa tên các file và nhãn dùng cho việc huấn luyện\n",
        "- **sample_submission.csv**: file CSV mẫu chứa tên các file cần đánh giá và nhãn dummy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3f7Xn6EFC-",
        "colab_type": "text"
      },
      "source": [
        "## Đọc và xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLFGYbfMWDQ7",
        "colab_type": "text"
      },
      "source": [
        "Đọc dữ liệu từ file CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH__gPbQJSLV",
        "colab_type": "code",
        "outputId": "526a7879-5537-4932-95be-3c2992fda689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VietAI-Assignment3-1.jpg</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VietAI-Assignment3-100.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VietAI-Assignment3-10000.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VietAI-Assignment3-10001.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VietAI-Assignment3-10002.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          image  label\n",
              "0      VietAI-Assignment3-1.jpg      7\n",
              "1    VietAI-Assignment3-100.jpg      2\n",
              "2  VietAI-Assignment3-10000.jpg      1\n",
              "3  VietAI-Assignment3-10001.jpg      2\n",
              "4  VietAI-Assignment3-10002.jpg      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBRrzcibWMWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syh-kjLNbiQd",
        "colab_type": "code",
        "outputId": "c2ffff43-5a9c-4efa-a34f-47479abb7d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VietAI-Assignment3-10.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VietAI-Assignment3-1000.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VietAI-Assignment3-10004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VietAI-Assignment3-10006.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VietAI-Assignment3-10012.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          image  label\n",
              "0     VietAI-Assignment3-10.jpg      0\n",
              "1   VietAI-Assignment3-1000.jpg      0\n",
              "2  VietAI-Assignment3-10004.jpg      0\n",
              "3  VietAI-Assignment3-10006.jpg      0\n",
              "4  VietAI-Assignment3-10012.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzBkL72Sbpg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buXAweOvENiO",
        "colab_type": "text"
      },
      "source": [
        "Tổng cộng có 8234 ảnh cho việc huấn luyện và 2059 ảnh cần dự đoán nhãn, ta tiến hành thống kê phân bố các nhãn trên tập huấn luyện:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZPoB7-gV8C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo0z1gUIVcmj",
        "colab_type": "text"
      },
      "source": [
        "Số lượng các ảnh cho mỗi lớp từ 400 đến 2000. Trong đó lớp số 2 có số lượng ảnh nhiều nhất"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtOnhMO_W_0D",
        "colab_type": "text"
      },
      "source": [
        "## TODO 1: Cài đặt hàm đọc ảnh và đưa về NumPy Array\n",
        "Để máy tính hiểu được các ảnh, chúng ta cần đọc và chuyển các ảnh về tensor. Bên cạnh đó, các tensor biểu diễn cần có kích thước cố định nên trong quá trình đọc ảnh, ta cần thay đổi về kích thước mong muốn (resize ảnh). Trong các bài toán về deep learning, ta thường biểu diễn ảnh dưới dạng tensor có kích thước `(224,224,3)` với 3 kênh màu, 224 pixels cho mỗi chiều.\n",
        "\n",
        "Hoàn thành hàm `generate_data` bên dưới nhận vào 1 list N đường dẫn đến ảnh và kích thước `size` ảnh cần resize. Trả về numpy array có kích thước `(N,size,size,3)` với các giá trị được normalized trong khoảng \\[0 ; 1\\]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIHjhdzRZ8Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(image_paths, size=224):\n",
        "    \"\"\"\n",
        "    Đọc và chuyển các ảnh về numpy array\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_paths: list of N strings\n",
        "        List các đường dẫn ảnh\n",
        "    size: int\n",
        "        Kích thước ảnh cần resize\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    numpy array kích thước (N, size, size, 3)\n",
        "    \"\"\"\n",
        "    image_array = np.zeros((len(image_paths), size, size, 3), dtype='float32')\n",
        "    \n",
        "    for idx, image_path in tqdm(enumerate(image_paths)):\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Đọc ảnh bằng thư viện Pillow và resize ảnh\n",
        "        image = Image.open(image_path).convert(\"RGB\").resize((size,size))\n",
        "        \n",
        "        # Chuyển ảnh thành numpy array và gán lại mảng image_array\n",
        "        image_array[idx] = np.array(image).astype('float32')/255\n",
        "        \n",
        "        ### END CODE HERE\n",
        "    return image_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9sI7QBibZdG",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng hàm `generate_data` để tạo ma trận của tập dữ liệu train và test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7UkA-_rbYzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List các đường dẫn file cho việc huấn luyện\n",
        "train_files = [os.path.join(\"data/images\", file) for file in train_df.image]\n",
        "\n",
        "# List các nhãn\n",
        "train_y = train_df.label\n",
        "\n",
        "# Tạo numpy array cho dữ liệu huấn luyện\n",
        "train_arr = generate_data(train_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9GkJ4Bfe2qc",
        "colab_type": "text"
      },
      "source": [
        "Hãy kiểm tra kích thước của tensor `train_arr` vừa tạo ra. Kích thước đúng sẽ là `(8234,224,224,3)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxScb0w_e2Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_arr.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msp9WEgOfRdf",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành tạo tensor dữ liệu cho tập test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vI-AlLgfXi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_files = [os.path.join(\"data/images\", file) for file in test_df.image]\n",
        "test_x = generate_data(test_files)\n",
        "test_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LssbDy2pf9ua",
        "colab_type": "text"
      },
      "source": [
        "Tạo **one-hot labels** từ `train_y` để đưa vào huấn luyện với Tensorflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVuRanKET6MO",
        "colab": {}
      },
      "source": [
        "num_classes = len(np.unique(train_y))\n",
        "y_one = tf.keras.utils.to_categorical(train_y, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vjpnYIXRT6MT"
      },
      "source": [
        "## Chia dữ liệu để huấn luyện và đánh giá\n",
        "\n",
        "Ta sẽ không sử dụng 100% tập dữ liệu đã có nhãn để huấn luyện mà sẽ chỉ huấn luyện trên 75% bộ dữ liệu và sử dụng 25% còn lại dùng để đánh giá model qua các epoch.\n",
        "\n",
        "Chúng ta sử dụng hàm `train_test_split` trong thư viện sklearn để chia tập dữ liệu thành 2 phần train/validation một cách nhanh chóng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MtnwiHOZT6MU",
        "colab": {}
      },
      "source": [
        "x_train, x_valid, y_train_one, y_valid_one = train_test_split(train_arr, y_one, test_size=0.25)\n",
        "\n",
        "print(\"Train size: {} - Validation size: {}\".format(x_train.shape, x_valid.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qCTUEY2dBIUQ",
        "colab": {}
      },
      "source": [
        "new_train_df, val_df = train_test_split(train_df, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "06g6e_u7T6MY"
      },
      "source": [
        "## Mô Hình CNN\n",
        "\n",
        "CNN bao gồm tập hợp các lớp cơ bản bao sau: convolution layer + nonlinear layer (RELU, ...), pooling layer, fully connected layer. Các lớp này liên kết với nhau theo một thứ tự nhất định. Thông thường, một ảnh sẽ được lan truyền qua tầng convolution layer + nonlinear layer đầu tiên, sau đó các giá trị tính toán được sẽ lan truyền qua pooling layer, bộ ba convolution layer + nonlinear layer + pooling layer có thể được lặp lại nhiều lần trong network. Và sau đó được lan truyền qua tầng fully connected layer và softmax để tính xác suất ảnh đó chứa vật thế gì.\n",
        "\n",
        "![](https://pbcquoc.github.io/images/cnn_model.png)\n",
        "\n",
        "### Convolution Layer\n",
        "Convolution layer là lớp đầu tiên và cũng là lớp quan trọng nhất của mô hình CNN. Lớp này có chức năng chính là phát hiện các đặc trưng về không gian một cách hiệu quả. Trong tầng này có 4 đối tượng chính là: ma trận đầu vào, bộ **filter**, và **receptive field**, **feature map**. Conv layer nhận đầu vào là một ma trận 3 chiều và một bộ filter cần phải học. Bộ filters này sẽ trượt qua từng vị trí trên bức ảnh để tính tích chập (convolution) giữa bộ filter và phần tương ứng trên bức ảnh. Phần tương ứng này trên bức ảnh gọi là receptive field, tức là vùng mà một neuron có thể nhìn thấy để đưa ra quyết định, và mà trận cho ra bởi quá trình này được gọi là feature map. Để hình dung, các bạn có thể tưởng tượng, bộ filters giống như các tháp canh trong nhà tù quét lần lượt qua không gian xung quanh để tìm kiếm tên tù nhân bỏ trốn. Khi phát hiện tên tù nhân bỏ trốn, thì chuông báo động sẽ reo lên, giống như các bộ filters tìm kiếm được đặc trưng nhất định thì tích chập đó sẽ cho giá trị lớn. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://media.giphy.com/media/3orif7it9f4phjv4LS/giphy.gif\" />\n",
        "</div>\n",
        "\n",
        "Với ví dụ ở bên dưới, dữ liệu đầu vào ở là ma trận có kích thước 8x8x1, một bộ filter có kích thước 2x2x1, feature map có kích thước 7x7x1. Mỗi giá trị ở feature map được tính bằng tổng của tích các phần tử tương ứng của bộ filter 2x2x1 với receptive field trên ảnh. Và để tính tất cả các giá trị cho feature map, các bạn cần trượt filter từ trái sang phải, từ trên xuống dưới. Do đó, các bạn có thể thấy rằng phép convolution bảo toàn thứ tự không gian của các điểm ảnh. Ví dụ điểm góc trái của dữ liệu đầu vào sẽ tương ứng với bên một điểm bên góc trái của feature map. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_covolution_layer.png\" />\n",
        "</div>\n",
        "\n",
        "#### Tầng convolution như là feature detector \n",
        "\n",
        "Tầng convolution có chức năng chính là phát hiện đặc trưng cụ thể của bức ảnh. Những đặc trưng này bao gồm đặc trưng cơ bản là góc, cạnh, màu sắc, hoặc đặc trưng phức tạp hơn như texture của ảnh. Vì bộ filter quét qua toàn bộ bức ảnh, nên những đặc trưng này có thể nằm ở vị trí bất kì trong bức ảnh, cho dù ảnh bị xoay trái/phải thì những đặc trưng này vẫn bị phát hiện. \n",
        "\n",
        "Ở minh họa dưới, các bạn có một filter 5x5 dùng để phát hiện góc/cạnh, filter này chỉ có giá trị một tại các điểm tương ứng một góc cong. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature.png\" />\n",
        "</div>\n",
        "\n",
        "Dùng filter ở trên trượt qua ảnh của nhân vật Olaf trong trong bộ phim Frozen. Chúng ta thấy rằng, chỉ ở những vị trí trên bức ảnh có dạng góc như đặc trưng ở filter thì mới có giá trị lớn trên feature map, những vị trí còn lại sẽ cho giá trị thấp hơn. Điều này có nghĩa là, filter đã phát hiện thành công một dạng góc/cạnh trên dự liệu đầu vào. Tập hợp nhiều bộ filters sẽ cho phép các bạn phát hiện được nhiều loại đặc trưng khác nhau, và giúp định danh được đối tượng. \n",
        "\n",
        "<div class=\"img-div\" markdown=\"0\">\n",
        "    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature_ex.png\" />\n",
        "</div>\n",
        "\n",
        "#### Các tham số của tầng convolution: Kích thước bộ filter, stride và padding\n",
        "\n",
        "Kích thước bộ filters là một trong những siêu tham số quan trọng nhất của tầng convolution. Kích thước này tỉ lệ thuận với số lượng tham số cần học tại mỗi tầng convolution và là tham số quyết định receptive field của tầng này. Kích thước phổ biến nhất của bộ filter là 3x3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CATPodwfT6MZ"
      },
      "source": [
        "# Xây dựng mô hình\n",
        "Các bạn cần phải xây dựng mô hình CNN có kiến trúc sau đây. Bộ filter có kích thước 3x3. Đối với các tham số còn lại, các bạn có thể tự do lựa chọn để cho ra kết quả huấn luyện tốt nhất.\n",
        "\n",
        "![](https://github.com/pbcquoc/cnn/raw/master/images/cnn_architecture_2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HCXKoRsNT6Ma"
      },
      "source": [
        "## Định nghĩa block CNN\n",
        "Để hỗ trợ quá trình định nghĩa mô hình. Các bạn cần định nghĩa một block bao gồm 3 lớp sau: Conv2D, MaxPool2D, ReLU. Block này sẽ được tái sử dụng nhiều lần trong networks. Các layers cần được khai báo trong hàm init và được gọi trong hàm call. Hãy tham khảo ví dụ dưới đây.\n",
        "\n",
        "```python\n",
        "\n",
        "class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.cnn = tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1),  padding=\"same\")\n",
        "        \n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.cnn(inputs)\n",
        "\n",
        "        return x\n",
        "```\n",
        "\n",
        "Các tài liệu tham khảo:\n",
        "- [tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
        "- [tf.keras.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GkT5hTxjT6Mb",
        "colab": {}
      },
      "source": [
        "class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel, strides, padding):\n",
        "        '''\n",
        "        Khởi tạo Convolution Block với các tham số đầu vào\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        filters: int\n",
        "            số lượng filter\n",
        "        kernel: int\n",
        "            kích thước kernel\n",
        "        strides: int\n",
        "            stride của convolution layer\n",
        "        padding: str\n",
        "            Loại padding của convolution layer\n",
        "        \n",
        "        '''\n",
        "        \n",
        "        super(ConvBlock, self).__init__()\n",
        "        ## TODO 2\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Tạo layer Conv2D\n",
        "        self.cnn = tf.keras.layers.Conv2D(filters, (kernel, kernel), strides=(strides, strides), kernel_initializer='he_normal', padding=padding)\n",
        "        \n",
        "        # Tạo layer MaxPool2D\n",
        "        self.pool = tf.keras.layers.MaxPool2D((2,2), strides=(2,2))\n",
        "        \n",
        "        # Tạo các layer khác tùy ý nếu cần thiết\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        \n",
        "        ### END CODE HERE\n",
        "        \n",
        "        \n",
        "    def call(self, inputs):\n",
        "        '''\n",
        "        Hàm này sẽ được gọi trong quá trình forwarding của mạng\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs: tensor đầu vào\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        tensor\n",
        "            giá trị đầu ra của mạng\n",
        "        '''\n",
        "        \n",
        "        x = None\n",
        "        ## TODO 3\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Forward inputs qua từng layer và gán vào biến x để trả về\n",
        "        \n",
        "        x = self.cnn(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = tf.nn.relu(x)   \n",
        "        x = self.pool(x)\n",
        "        \n",
        "        ## END CODE HERE\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D1avJ7wvxpFq"
      },
      "source": [
        "## Định nghĩa toàn bộ mô hình CNN\n",
        "Các bạn sử dụng block ở trên để định nghĩa toàn bộ mô hình CNN có kiến trúc như hình dưới. Các layer cần được khởi tạo trong hàm init, và được gọi trong hàm call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fn6w7oh-T6Md",
        "colab": {}
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        \n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        ## TODO 4\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Khởi tạo các convolution block\n",
        "        self.block1 = ConvBlock(64, kernel=3, strides=1, padding='same')\n",
        "        self.block2 = ConvBlock(128, kernel=3, strides=1, padding='same')\n",
        "        self.block3 = ConvBlock(256, kernel=3, strides=1, padding='same')\n",
        "        self.block4 = ConvBlock(512, kernel=3, strides=1, padding='same')\n",
        "        self.block5 = ConvBlock(512, kernel=3, strides=1, padding='same')       \n",
        "        self.block6 = ConvBlock(1024, kernel=3, strides=1, padding='same')\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n",
        "        \n",
        "        # Khởi tạo layer để flatten feature map \n",
        "        self.flatten = tf.layers.Flatten()\n",
        "        \n",
        "        ### END CODE HERE\n",
        "        \n",
        "        ## TODO 5\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Khởi tạo fully connected layer\n",
        "        self.dense1 = tf.keras.layers.Dense(num_classes)\n",
        "        \n",
        "        ### END CODE HERE\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        ## TODO 6\n",
        "        x = None\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Forward gía trị inputs qua các tầng CNN và gán vào x\n",
        "        x = self.block1(inputs)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        ### END CODE HERE\n",
        "        \n",
        "        ## TODO 7\n",
        "        \n",
        "        ### START CODE HERE \n",
        "        \n",
        "        # Forward giá trị x qua Fully connected layer\n",
        "        x = self.dense1(x)\n",
        "        \n",
        "        ### END CODE HERE\n",
        "        \n",
        "        # Để sử dụng hàm softmax, ta phải thực thi trên CPU\n",
        "        with tf.device('/cpu:0'):\n",
        "            output = tf.nn.softmax(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K_jxGjdST6Mg"
      },
      "source": [
        "## TODO 2: Cài Đặt Block CNN trong lớp ConvBlock\n",
        "Sử dụng `tf.keras.layers.Conv2D` và `tf.keras.layers.MaxPool2D` để cài đặt tầng convolution và tầng pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_qngAyXgCt8B"
      },
      "source": [
        "## TODO 3: Gọi các tầng trong ConvBlock của lớp ConvBlock\n",
        "Hãy gọi các tầng đã cài đặt trọng lớp ConvBlock trong hàm call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DN3gs3aT6Mg"
      },
      "source": [
        "## TODO 4: Khai báo ConvBlock 1,2,3,4,5 trong mô hình CNN\n",
        "Gọi ConvBlock đã cài đặt ở trên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oj4C8OMZT6Mh"
      },
      "source": [
        "## TODO 5: Khai báo Tầng Fully Connected Layer cho mô hình CNN\n",
        "Gọi `tf.keras.layers.Dense` để cài đặt tầng này"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qO-PkgqyT6Mj"
      },
      "source": [
        "## TODO 6: Gọi các tầng Conv đã khai báo trong mô hình CNN ở trên\n",
        "Gọi các tầng Conv đã cài đặt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CkbJdSYmT6Mk"
      },
      "source": [
        "## TODO 7: Gọi tầng Fully Connected Layer\n",
        "Hãy flatten tầng phía trước và gọi tầng fully connected layer để convert về ma trận có số chiều bằng số lớp cần phân loại"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HeV9Ab03T6Mk"
      },
      "source": [
        "# Huấn Luyện\n",
        "Đoạn code này thực hiện quá trình huấn luyện mô hình CNN. Mỗi lần chạy mô hình sẽ lấy `batch_size` mẫu dữ liệu, feedforward, tính loss, và cập nhật gradient cho toàn bộ trọng số. Toàn bộ quá trình này được thực hiện trong hàm `fit()` được build sẵn trong model keras.\n",
        "\n",
        "Sau khi huấn luyện xong, chúng ta sẽ sử dụng mô hình để phân lớp các ảnh trong tập test bằng hàm `predict()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5tmZonE2T6Ml",
        "colab": {}
      },
      "source": [
        "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
        "batch_size = 32\n",
        "epochs = 16\n",
        "\n",
        "with tf.device(device):\n",
        "    # Khởi tạo model\n",
        "    model = CNN(num_classes)\n",
        "    \n",
        "    # Tạo callback để lưu model có accuracy trên tập validation tốt nhất\n",
        "    mcp = tf.keras.callbacks.ModelCheckpoint(\"my_model.h5\", monitor=\"val_acc\",\n",
        "                      save_best_only=True, save_weights_only=True)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Huấn luyện\n",
        "    print(y_train_one)\n",
        "    model.fit(x_train, y_train_one, batch_size=batch_size, epochs=epochs,\n",
        "              validation_data=(x_valid, y_valid_one), verbose=1, callbacks=[mcp])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5p4QgrUJT6Mp"
      },
      "source": [
        "# Dự Đoán các ảnh trên tập test\n",
        "\n",
        "Chúng ta sử dụng mô hình đã được huấn luyện bên trên để dự đoán cho các ảnh trong tập test, xuất ra file CSV và submit kết quả lên Kaggle:\n",
        "\n",
        "[Link nộp kết quả](https://www.kaggle.com/c/vietai-fc-cnn-assignment/submissions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np3O0GgN4s3n",
        "colab_type": "text"
      },
      "source": [
        "## Tạo và load model đã lưu trước đó"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VnnCTqhBT6Mq",
        "colab": {}
      },
      "source": [
        "# Load best model\n",
        "model = CNN(11)\n",
        "\n",
        "# Thiết lập kích thước input cho model\n",
        "dummy_x = tf.zeros((1, 224, 224, 3))\n",
        "model._set_inputs(dummy_x)\n",
        "\n",
        "# Load model đã lưu trước đó trong quá trình huấn luyện\n",
        "model.load_weights('my_model.h5')\n",
        "print(\"Model đã được load\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaMQvDMJ46Vs",
        "colab_type": "text"
      },
      "source": [
        "## Dự đoán nhãn của các ảnh trên tập test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLaGW2b55mqW",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng hàm predict để dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TBl_-M0_T6Mt",
        "colab": {}
      },
      "source": [
        "pred = model.predict(test_x)\n",
        "\n",
        "# pred là một ma trận xác suất của ảnh trên các lớp.\n",
        "# Ta lấy lớp có xác suất cao nhất trên từng ảnh bằng hàm argmax\n",
        "pred_labels = np.argmax(pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqXMbQte5o7U",
        "colab_type": "text"
      },
      "source": [
        "Hiển thị thử kết quả của tập test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhVAFRO3T6Nn",
        "colab": {}
      },
      "source": [
        "test_df['label'] = predictions\n",
        "test_df.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlJ9T6eN5u9n",
        "colab_type": "text"
      },
      "source": [
        "Lưu kết quả thành file CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx7VJJnCozqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLo6SJb-AjWD",
        "colab_type": "text"
      },
      "source": [
        "## Nộp kết quả lên Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9oGE4zfA5J9",
        "colab_type": "text"
      },
      "source": [
        "1. Truy cập vào [Kaggle](https://www.kaggle.com), đăng ký/ đăng nhập tài khoản\n",
        "\n",
        "2. Truy cập vào đường dẫn của competition [VietAI Foundation Course - CNN Assignment](https://www.kaggle.com/t/1ca504e0910d4bfc9ba0ad0ffca12e2e)\n",
        "\n",
        "3. Nhấn vào nút **Join Competition**\n",
        "![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.48.12.png)\n",
        "\n",
        "4. Nhấn vào nút **I Understand and Accept**\n",
        "![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.48.52.png)\n",
        "\n",
        "5. Chọn **Team**\n",
        "![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.49.43.png)\n",
        "\n",
        "6. Đặt team name theo đúng họ và tên của bạn và bấm **Save team name**\n",
        "![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.50.30.png)\n",
        "\n",
        "7. Để nộp file CSV vừa tạo, các bạn nhấp vào **Submit Predictions**\n",
        " ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.51.39.png)\n",
        " \n",
        "8. Upload file CSV và nộp\n",
        " ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.52.19.png)\n",
        "\n",
        "9. Sau khi nộp, màn hình sẽ hiện ra kết quả, để biết vị trí mình trên leaderboard, các bạn nhấp vào **Jump to your position on the leaderboard**\n",
        " ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.55.23.png)\n",
        "\n",
        "10. Leaderboard sẽ như sau:\n",
        " ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.55.32.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UJBk2YToUAW",
        "colab_type": "text"
      },
      "source": [
        "# Baseline model 2: Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udb21Jh3o0Jv",
        "colab_type": "text"
      },
      "source": [
        "Ở baseline này, để cải thiện kết quả trên tập test, chúng ta có thể áp dụng kỹ thuật Image Augmentation. Thư viện Keras hỗ trợ class `ImageDataGenerator` trong việc augmentation. Ở ví dụ bên dưới, các kỹ thuật được áp dụng trong quá trình xử lý ảnh là:\n",
        "- rescale: đưa ảnh về miền giá trị [0,1]\n",
        "- rotation: xoay ảnh ngẫu nhiên trái phải 20 độ\n",
        "- shift: dịch chuyển ảnh sang trái phải, trên dưới 20% kích thước\n",
        "- horizontal flip: lật ảnh ngang ngẫu nhiên\n",
        "\n",
        "Tuy nhiên các kĩ thuật này chỉ áp dụng trong khi training, khi validation và testing, chỉ có rescale được áp dụng để tránh việc các kết quả validation không chính xác do data thay đổi qua các lần validate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQA6Xz2thtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Generator dùng cho training\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Data Generator dùng cho validation và testing\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDGDU84TqDgU",
        "colab_type": "text"
      },
      "source": [
        "Class `ImageDataGenerator` hỗ trợ đọc ảnh và augmentation realtime khi training, điều này giúp cho quá trình training không tốn nhiều bộ nhớ do không cần phải load toàn bộ ảnh như ban đầu. Ta có thể sử dụng hàm `flow_from_dataframe` để tạo luồng input từ DataFrame và folder chứa ảnh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSYU4w2Dt73d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 24\n",
        "\n",
        "# ImageDataGenerator chỉ chấp nhận kiểu label là string, \n",
        "# ta chuyển cột label sang string\n",
        "train_df[\"label\"] = train_df[\"label\"].map(lambda x: str(x))\n",
        "# Chia dữ liệu thành train và validation\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.25)\n",
        "\n",
        "# Tạo luồng dữ liệu cho quá trình train, các bạn có thể tìm hiểu các tham số ở Keras document\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe=train_data, \n",
        "                                        directory=\"data/images\", \n",
        "                                        x_col=\"image\", \n",
        "                                        y_col=\"label\",\n",
        "                                        class_mode=\"categorical\",\n",
        "                                        target_size=(224,224), \n",
        "                                        batch_size=batch_size)\n",
        "\n",
        "# Tạo luồng dữ liệu cho quá trình test\n",
        "val_gen = test_datagen.flow_from_dataframe(dataframe=val_data, \n",
        "                                        directory=\"data/images\", \n",
        "                                        x_col=\"image\", \n",
        "                                        y_col=\"label\",\n",
        "                                        class_mode=\"categorical\",\n",
        "                                        shuffle=False,\n",
        "                                        target_size=(224,224), \n",
        "                                        batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl1UAMp8q51Z",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usWQsXR3q0b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = '/cpu:0' if tfe.num_gpus() == 0 else '/gpu:0'\n",
        "epochs = 50\n",
        "\n",
        "# Số lượng training step mỗi epoch\n",
        "steps_per_epoch = train_gen.n // batch_size\n",
        "# Số lượng validation step\n",
        "validation_steps = val_gen.n // batch_size\n",
        "\n",
        "with tf.device(device):\n",
        "    # Khởi tạo model\n",
        "    model = CNN(num_classes)\n",
        "    \n",
        "    # Lưu ý, để sử dụng hàm fit_generator ta cần set kích thước input\n",
        "    # dummy_x = tf.zeros((1, 224, 224, 3))\n",
        "    # model._set_inputs(dummy_x)\n",
        "    \n",
        "    # Tạo callback để lưu model có accuracy trên tập validation tốt nhất\n",
        "    mcp = tf.keras.callbacks.ModelCheckpoint(\"cnn_augmentation.h5\", monitor=\"val_acc\",\n",
        "                      save_best_only=True, save_weights_only=True)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Huấn luyện với data generator\n",
        "    model.fit_generator(train_gen, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=epochs,\n",
        "                        verbose=1, \n",
        "                        validation_data=val_gen,\n",
        "                        validation_steps=validation_steps, \n",
        "                        callbacks=[mcp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VW8rt8VrkC7",
        "colab_type": "text"
      },
      "source": [
        "Để predict trên tập test, ta cũng tạo một data generator với `class_mode` là `None`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTWHpPVyQR3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen = test_datagen.flow_from_dataframe(dataframe=test_df, \n",
        "                                        directory=\"data/images\", \n",
        "                                        x_col=\"image\",\n",
        "                                        class_mode=None,\n",
        "                                        shuffle=False,\n",
        "                                        batch_size=32,\n",
        "                                        target_size=(224,224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaNHbhX6r1SQ",
        "colab_type": "text"
      },
      "source": [
        "Lưu ý, thứ tự các lớp sẽ không tuân theo quy luật từ 0-10 mà sẽ theo thứ tự alphabet khi sử dụng ImageDataGenerator. Do đó ta cần ánh xạ các indices sau khi predict về lớp tương ứng của nó:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVb_cZ-Aoj5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_generator(test_gen)\n",
        "\n",
        "# pred là một ma trận xác suất của ảnh trên các lớp.\n",
        "# Ta lấy lớp có xác suất cao nhất trên từng ảnh bằng hàm argmax\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\n",
        "\n",
        "# Dictionary ánh xạ nhãn và index\n",
        "labels = train_gen.class_indices\n",
        "\n",
        "# Ánh xạ indices về nhãn đúng\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Nqn8V-soax",
        "colab_type": "text"
      },
      "source": [
        "Sau bước này, ta tạo file submission và nộp kết quả như ở baseline đầu tiên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBTLU_fwswBx",
        "colab_type": "text"
      },
      "source": [
        "# Baseline model 3: Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexvLhS5s0YE",
        "colab_type": "text"
      },
      "source": [
        "Ở bài học trước đây, chúng ta đã học về phương pháp Transfer Learning và các kiến trúc phổ biến trên tập ImageNet. Ở baseline model 3 này, mình sẽ hướng dẫn các bạn áp dụng transfer learning cho bài toán này. Các bước rất đơn giản nhưng bạn có thể tạo ra model có F-1 score lên đến 0.95. Ở baseline này, mình sử dụng ResNet50 và huấn luyện theo chiến thuật: ***Freeze các lớp CNN và huấn luyện lớp classifier với learning rate lớn sau đó unfreeze toàn bộ mạng và huấn luyện với learning rate nhỏ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uDe_bao6we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install effiecientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOQNzAFOp9qz",
        "colab_type": "code",
        "outputId": "03ab0c58-e694-4dd3-a15d-2c8deabf8bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from effiecientnet improt EfficientNetB3\n",
        "import keras\n",
        "from efficientnet.keras import EfficientNetB3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diBHD1ShNxL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM4TR8rlqB2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Số lượng training step mỗi epoch\n",
        "steps_per_epoch = train_gen.n // batch_size\n",
        "# Số lượng validation step\n",
        "validation_steps = val_gen.n // batch_size\n",
        "\n",
        "# Khởi tạo base model Resnet với pretrained weights từ ImageNet\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Tạo model hoàn chỉnh bằng cách thêm lớp classifier\n",
        "x = base_model.output\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "predictions = keras.layers.Dense(11, activation='softmax')(x)\n",
        "model = keras.models.Model(input = base_model.input, output = predictions)\n",
        "\n",
        "# Freeze các lớp CNN ban đầu\n",
        "base_model.trainable = False\n",
        "\n",
        "# Tạo callback để lưu model có accuracy trên tập validation tốt nhất\n",
        "mcp = keras.callbacks.ModelCheckpoint(\"efficientnetb3.h5\", monitor=\"val_f1\",\n",
        "                  save_best_only=True, mode='max', save_weights_only=True, verbose=1)\n",
        "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_f1', factor=0.1, mode='max', patience=5, min_lr=1e-8, verbose=1)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=keras.optimizers.Adam(0.01), loss='categorical_crossentropy',\n",
        "              metrics=[f1])\n",
        "\n",
        "# model.load_weights(\"efficientnetb3.h5\")\n",
        "\n",
        "# Huấn luyện 10 epochs với learning rate lớn\n",
        "model.fit_generator(train_gen, \n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    epochs=10,\n",
        "                    verbose=1, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=validation_steps, \n",
        "                    callbacks=[mcp, rlr])\n",
        "\n",
        "# Unfreeze toàn bộ mạng\n",
        "base_model.trainable = True\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=keras.optimizers.Adam(0.01), loss='categorical_crossentropy',\n",
        "              metrics=[f1])\n",
        "\n",
        "\n",
        "\n",
        "# Huấn luyện 100 epochs với learning rate nhỏ\n",
        "model.fit_generator(train_gen, \n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    epochs=100,\n",
        "                    verbose=1, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=validation_steps, \n",
        "                    callbacks=[mcp])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqHSMra3gFZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device(device):\n",
        "    # Khởi tạo base model Resnet với pretrained weights từ ImageNet\n",
        "    base_model = tf.keras.applications.ResNet50(input_shape=(224,224,3),\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "    \n",
        "    # Tạo model hoàn chỉnh bằng cách thêm lớp classifier\n",
        "    model = tf.keras.Sequential([\n",
        "      base_model,\n",
        "      keras.layers.GlobalAveragePooling2D(),\n",
        "      keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # Freeze các lớp CNN ban đầu\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Tạo callback để lưu model có accuracy trên tập validation tốt nhất\n",
        "    mcp = tf.keras.callbacks.ModelCheckpoint(\"resnet50.h5\", monitor=\"val_acc\",\n",
        "                      save_best_only=True, save_weights_only=True)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(0.01), loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Huấn luyện 10 epochs với learning rate lớn\n",
        "    model.fit_generator(train_gen, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=10,\n",
        "                        verbose=1, \n",
        "                        validation_data=val_gen,\n",
        "                        validation_steps=validation_steps, \n",
        "                        callbacks=[mcp])\n",
        "    \n",
        "    # Unfreeze toàn bộ mạng\n",
        "    base_model.trainable = True\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Huấn luyện 100 epochs với learning rate nhỏ\n",
        "    model.fit_generator(train_gen, \n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        epochs=100,\n",
        "                        verbose=1, \n",
        "                        validation_data=val_gen,\n",
        "                        validation_steps=validation_steps, \n",
        "                        callbacks=[mcp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPaZVmoEuSBQ",
        "colab_type": "text"
      },
      "source": [
        "# Các phương pháp khác\n",
        "Ngoài các baseline models được giới thiệu ở trên, các bạn hoàn toàn có thể sử dụng thêm các phương pháp khác như:\n",
        "- Sử dụng thư viện augmentation phức tạo hơn `imgaug`.\n",
        "- Oversampling để làm tăng độ cân bằng của dữ liệu.\n",
        "- Thêm weights vào hàm loss để làm tăng độ cân bằng giữa các nhãn.\n",
        "- Sử dụng các kiến trúc CNN khác, hoặc kết hợp nhiều kiến trúc lại với nhau.\n",
        "- Sử dụng ten-crop validation khi testing.\n",
        "- Sử dụng các phương pháp cross-validation để chia dữ liệu khi huấn luyện."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6s3K6tHQ3JP",
        "colab_type": "text"
      },
      "source": [
        "# Authors: Quoc Pham, Chuong Huynh"
      ]
    }
  ]
}